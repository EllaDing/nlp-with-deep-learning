\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{amsfonts}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{float}
\usepackage{color}
\usepackage{url}
\usepackage{amsmath}
\definecolor{backcolour}{rgb}{0.96,0.96,0.96}
\definecolor{commentgreen}{rgb}{0.3,0.6,0.75}
\definecolor{keywordgreen}{rgb}{0.15,0.5,0.15}
\definecolor{stringmaroon}{rgb}{0.5,0,0}
\usepackage{amsmath}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\usepackage{geometry}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{commentgreen},
    keywordstyle=\color{keywordgreen},
    stringstyle=\color{stringmaroon},
    basicstyle=\footnotesize\ttfamily,
    breaklines=true,
    captionpos=b,                    
    keepspaces=false,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=4
}
\lstset{style=mystyle}
\title{Assignment4}
\begin{document}
\maketitle
\section{Neural Machine Translation with RNNs}
(g) The mask is used for setting padding words' weights(attention distribution score) to $-inf$, i.e. it sets the impact of padding words in source sentence to minimal for decoder. It is useful because the decoder should only pay attention to those real words rather than padding words in source sentence.\\\\
(i) Dot product attention vs Multiplicative attention \\
Dot product attention: Pros: Fewer parameters. Faster and space-efficient. Cons: If attention output vector is not in the same space as decoder's hidden state, the learned result may be not that optimal.\\\\
Multiplicative attention vs additive attention.\\
Additive attention: Pros: Captures non-linear interaction between decoder's attention output and encoder's hidden state. Cons: Computation is slower.
\section{Analyzing NMT Systems}
\end{document} 

